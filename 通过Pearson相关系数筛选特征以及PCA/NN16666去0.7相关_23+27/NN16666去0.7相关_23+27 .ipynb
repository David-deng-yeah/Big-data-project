{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc436b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29695e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block1=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Blocks/Block 1.csv')\n",
    "# Block2=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Blocks/Block 2.csv')\n",
    "\n",
    "Block=np.vstack((\n",
    "    pd.read_csv('Blocks/Block 31.csv').drop(['27','23'],axis=1).values,\n",
    "    pd.read_csv('Blocks/Block 32.csv').drop(['27','23'],axis=1).values\n",
    "))\n",
    "\n",
    "test=pd.read_csv('test.csv').drop(['27','23'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6750f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5faf020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=torch.FloatTensor(Block[:,1:]).cuda('cuda:0')\n",
    "Y=  torch.LongTensor(Block[:,0]).cuda('cuda:0')\n",
    "\n",
    "X_test_all=torch.FloatTensor(test.drop('label',axis=1).values).cuda('cuda:0')\n",
    "Y_test_all=             torch.LongTensor(test['label'].values).cuda('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5463a480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavier初始化权重\n",
    "\n",
    "def xavier(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super().__init__()\n",
    "        self.f1=nn.Linear(input_dim,input_dim*6)\n",
    "        self.drop1=nn.Dropout(p=0.2)\n",
    "        self.s1=nn.ReLU()\n",
    "        \n",
    "        self.f2=nn.Linear(input_dim*6,input_dim*6)\n",
    "        self.drop2=nn.Dropout(p=0.3)\n",
    "        self.s2=nn.ReLU()\n",
    "        \n",
    "        self.f3=nn.Linear(input_dim*6,input_dim*6)\n",
    "        self.drop3=nn.Dropout(p=0.5)\n",
    "        self.s3=nn.ReLU()    \n",
    "        \n",
    "        self.f4=nn.Linear(input_dim*6,input_dim*6)\n",
    "        self.drop4=nn.Dropout(p=0.3)\n",
    "        self.s4=nn.ReLU()\n",
    "        \n",
    "        self.f5=nn.Linear(input_dim*6,input_dim*6)\n",
    "        self.drop5=nn.Dropout(p=0.2)\n",
    "        self.s5=nn.ReLU()\n",
    "            \n",
    "        self.f6=nn.Linear(input_dim*6,2)   \n",
    "        self.s6=nn.Softmax(dim=1)\n",
    "        \n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.s1(self.drop1(self.f1(x)))\n",
    "        x=self.s2(self.drop2(self.f2(x)))\n",
    "        x=self.s3(self.drop3(self.f3(x)))\n",
    "        x=self.s4(self.drop4(self.f4(x)))\n",
    "        x=self.s5(self.drop5(self.f5(x)))\n",
    "        return self.s6(self.f6(x))\n",
    "        \n",
    "#     预测\n",
    "    def predict(self,x):\n",
    "        with torch.no_grad():\n",
    "            x=self.s1(self.f1(x))\n",
    "            x=self.s2(self.f2(x))\n",
    "            x=self.s3(self.f3(x))\n",
    "            x=self.s4(self.f4(x))\n",
    "            x=self.s5(self.f5(x))\n",
    "            p=self.s6(self.f6(x))\n",
    "            return (p[:,0]<p[:,1])\n",
    "    \n",
    "#     准确率 \n",
    "    def acc(self,x,y):\n",
    "        with torch.no_grad():\n",
    "            return float(((self.predict(x)==y).sum()/len(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37c047fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=MyNet(X.shape[1]).cuda(\"cuda:0\")\n",
    "net.apply(xavier);\n",
    "\n",
    "net.load_state_dict(torch.load('Params/NN16666去0.7相关_23+27/Net 3300.params'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e265193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用于绘制曲线\n",
    "losses=[]\n",
    "train_acc=[]\n",
    "test_acc=[]\n",
    "\n",
    "# 用于随机抽测试集\n",
    "idx=list(range(len(test)))\n",
    "n_train=len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0821cfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 184.00 MiB (GPU 0; 4.00 GiB total capacity; 2.76 GiB already allocated; 0 bytes free; 2.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-203b5e00ef6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-1b20c3afb5a7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ms4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anacodna3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anacodna3\\lib\\site-packages\\torch\\nn\\modules\\dropout.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anacodna3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1167\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1168\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[1;34m\"but got {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1169\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 184.00 MiB (GPU 0; 4.00 GiB total capacity; 2.76 GiB already allocated; 0 bytes free; 2.97 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "optimizer=torch.optim.Adam(net.parameters(), lr=0.0125, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.000001, amsgrad=False)\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "epochs=100\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    \n",
    "    y_pred=net.forward(X)\n",
    "    loss=criterion(y_pred,Y)\n",
    "    \n",
    "\n",
    "    if(i%100)==0:\n",
    "        losses.append(float(loss))\n",
    "        train_acc.append( net.acc(X,Y) )\n",
    "        \n",
    "        np.random.shuffle(idx)\n",
    "\n",
    "        X_test=X_test_all[idx[n_train:n_train*2]].cuda('cuda:0')\n",
    "        Y_test=Y_test_all[idx[n_train:n_train*2]].cuda('cuda:0')\n",
    "        \n",
    "        test_acc.append(net.acc(X_test,Y_test))\n",
    "        \n",
    "    if(i%(int(epochs*0.1))==0):\n",
    "        print(str((i/epochs)*100)+'%',end='\\t')\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print('100%')\n",
    "torch.save(net.state_dict(),'Params/NN16666去0.7相关_23+27/Net '+str(len(train_acc)*100)+'.params')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f456aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_acc=net.acc(X,Y)\n",
    "te_acc=net.acc(X_test,Y_test)\n",
    "\n",
    "%matplotlib inline\n",
    "fig,ax=plt.subplots(1,2,figsize=(16,6))\n",
    "\n",
    "ax[0].set_xlabel('x100 epochs')\n",
    "ax[0].set_title('Loss')\n",
    "ax[0].plot(   losses,label='Train loss')\n",
    "ax[1].plot(train_acc,label='Train acc = '+str(tr_acc))\n",
    "ax[1].plot( test_acc,label='Test acc = '+str(te_acc))\n",
    "ax[1].set_xlabel('x100 epochs')\n",
    "ax[1].set_title('Accuracy')\n",
    "plt.legend()\n",
    "print('epoch: '+str(len(train_acc*100)))\n",
    "print('Train acc: ',net.acc(X,Y))\n",
    "print('Test acc:  ',net.acc(X_test,Y_test))\n",
    "plt.savefig('Params/NN16666去0.7相关_23+27/Net'+str(len(train_acc)*100)+'.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db3c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bff199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968fa9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
